{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71851211",
   "metadata": {},
   "source": [
    "# Домашнее задание: Реализация алгоритмов PC (Peter‑Clark) и Greedy Equivalence Search (GES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d2d73",
   "metadata": {},
   "source": [
    "В этом задании необходимо реализовать два классических алгоритма построения причинно‑следственных графов:\n",
    "\n",
    "* **PC‑алгоритм** (Peter‑Clark) — constraint‑based метод, основанный на статистических тестах.\n",
    "* **Greedy Equivalence Search (GES)** — score‑based метод, основанный на жадном поиске по эквивалентным классам DAG.\n",
    "\n",
    "Неплохой обзор на эти и другие подходы к восстановлению причинно-следственных связей в данных можно найти [здесь](https://www.frontiersin.org/journals/genetics/articles/10.3389/fgene.2019.00524/full)."
   ]
  },
  {
   "cell_type": "code",
   "id": "61362e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:02.458463Z",
     "start_time": "2025-05-03T10:45:02.427894Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "e9816fef",
   "metadata": {},
   "source": [
    "## Часть 1. PC‑алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d1986",
   "metadata": {},
   "source": [
    "\n",
    "Алгоритм PC состоит из трех частей:\n",
    "\n",
    "1. **Построение скелета графа** — итеративно удаляем ребра если находим (условную) независимость между переменными $i$ и $j$ относительно некоторого множества $S \\subset V$ \\ $\\{i, j\\}$ .\n",
    "2. **Поиск v-структур** — ориентируем некоторые тройки вершин i - j - k (unshielded triple) как i -> j <- k (v-structure).\n",
    "2. **Ориентация рёбер относительно правил Мика** — применяем набор эвристических правил для получения ориентированного ациклического графа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ada35",
   "metadata": {},
   "source": [
    "Реализуйте [z-тест Фишера](https://en.wikipedia.org/wiki/Partial_correlation) на условную независимость переменных X и Y относительно множества Z -- данная функция понадобится в 1 и 2 частях:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:02.485943Z",
     "start_time": "2025-05-03T10:45:02.470707Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy.stats import norm",
   "id": "4b13001d25a7eac7",
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "2d017849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:02.540776Z",
     "start_time": "2025-05-03T10:45:02.520396Z"
    }
   },
   "source": [
    "def indep_test(X: str, Y: str, Z: set[str], data: pd.DataFrame, alpha: float = 0.05):\n",
    "    \"\"\"Возвращает `True`, если X ⟂ Y | Z.\"\"\"\n",
    "    \n",
    "    # Для вычисления выборочной частной корреляции для некоторых данных воспользуемся инверсией корреляционной матрицы\n",
    "    \n",
    "    # Подготовим данные:\n",
    "    columns = [X, Y] + list(Z) \n",
    "    df = data[columns].dropna() # Тут мы удаляем все строки с пропусками\n",
    "    N = df.shape[0]\n",
    "\n",
    "    # Проверочка на возможность применения z-тест Фишера:\n",
    "    if N - len(Z) - 3 <= 0:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    if not Z:\n",
    "        # При отсутствии Z просто считаем обычную корреляцию Пирсона:\n",
    "        # Corr(X, Y) = Cov(X, Y)/(sigma_X * sigma_Y)\n",
    "        r = df[X].corr(df[Y])\n",
    "    else:\n",
    "        # Находим корреляционную матрицу для X, Y, Z; инвертируем её получая матрицу точности \n",
    "        corr_matrix = df.corr().to_numpy()\n",
    "        precision_matrix = np.linalg.inv(corr_matrix)\n",
    "\n",
    "        # Индексы X и Y\n",
    "        x, y = 0, 1\n",
    "\n",
    "        # Воспользуемся основной формулой частичной корреляции через матрицу точности:\n",
    "        # r_x,y = - (ro_x,y)/(sqrt(ro_x,x * ro_y,y))\n",
    "        r = - precision_matrix[x, y] / np.sqrt(precision_matrix[x, x] * precision_matrix[y, y])\n",
    "\n",
    "\n",
    "\n",
    "    # Воспользуемся z-преобразование Фишера:\n",
    "    # z(r_x,y) = 1/2 * ln((1 + r_x,y)/(1 - r_x,y))\n",
    "    z_transform = 0.5 * np.log((1 + r) / (1 - r))\n",
    "\n",
    "    # Считаем тестовую статистику:\n",
    "    # sqrt(N - |Z| - 3) * |z_transform|\n",
    "    test_stat = np.sqrt(N - len(Z) - 3) * abs(z_transform)\n",
    "\n",
    "    # Теперь высчитаем критическое значение нормального распределения:\n",
    "    # Fi^(-1)((1 - alpha) / 2)\n",
    "    critical_value = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    # Проверка гипотезы\n",
    "    # Мы можем отклонить H_0, если тестовая статистика будет больше критического значения норм. распред.\n",
    "    if test_stat > critical_value:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "5d2ddaf6",
   "metadata": {},
   "source": [
    "### 1.1 Функция `estimate_skeleton`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c126a",
   "metadata": {},
   "source": [
    "На данном этапе формируется скелет графа путём последовательного удаления рёбер из исходного полносвязного графа. Для каждой пары вершин $X$ и $Y$ выполняется тест на условную независимость $X$ ⊥ $Y$ ∣ $Z$: если найдётся хотя бы одно множество $Z$ при котором эта независимость подтверждается, то ребро $X$ - $Y$ удаляется."
   ]
  },
  {
   "cell_type": "code",
   "id": "4922c1a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:02.575045Z",
     "start_time": "2025-05-03T10:45:02.557546Z"
    }
   },
   "source": [
    "\n",
    "def estimate_skeleton(data: pd.DataFrame, indep_test, alpha: float = 0.05):\n",
    "    \"\"\"Оценивает неориентированный скелет графа.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Входные данные, столбцы — переменные.\n",
    "    indep_test : callable\n",
    "        Функция для проверки условной независимости (см. ниже).\n",
    "    alpha : float\n",
    "        Порог значимости для теста.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    skeleton : nx.Graph\n",
    "        Неориентированный граф после удаления зависимых рёбер.\n",
    "    \"\"\"\n",
    "    # Первый шаг - построение полного неориентированного графа:\n",
    "    variables = list(data.columns)\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(variables)\n",
    "    graph.add_edges_from(combinations(variables, 2))\n",
    "\n",
    "    # Основная идея:\n",
    "    # Необходимо сформировать полный неориентированных граф \n",
    "    # После, мы будем устранять ребра между переменными, которые оказываются условно независимыми при некотором множестве других переменных (Z).\n",
    "    \n",
    "    # sep_sets - тут у нас все множества Z, при которых выполнилось условие о независимости переменных\n",
    "    # size_of_Z_set - размер ;)\n",
    "    sep_sets = {} \n",
    "    size_of_Z_set = 0      \n",
    "    \n",
    "    while True:\n",
    "        # Флаг, просто флаг\n",
    "        any_candidate = False\n",
    "        edges = list(graph.edges())\n",
    "\n",
    "        for X, Y in edges:\n",
    "            neighbours = (set(graph.neighbors(X)) | set(graph.neighbors(Y))) - {X, Y}\n",
    "\n",
    "            # Условие о размерности множества Z и кол-ве самих соседей \n",
    "            if len(neighbours) < size_of_Z_set:\n",
    "                continue\n",
    "\n",
    "            any_candidate = True\n",
    "\n",
    "            for Z in combinations(neighbours, size_of_Z_set):\n",
    "                if indep_test(X, Y, set(Z), data, alpha):\n",
    "                    graph.remove_edge(X, Y)\n",
    "                    # Запомни Z мн-во, которое разделило ребра X и Y\n",
    "                    sep_sets[frozenset((X, Y))] = set(Z)\n",
    "                    break\n",
    "\n",
    "        # Условие выхода из цикла:\n",
    "        if not any_candidate:\n",
    "            break\n",
    "        size_of_Z_set += 1\n",
    "    \n",
    "    # Прикрепим sep_sets \n",
    "    graph.graph[\"sep_sets\"] = sep_sets\n",
    "    \n",
    "    return graph, sep_sets\n"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "e9f8d305",
   "metadata": {},
   "source": [
    "### 1.2 Функция `find_colliders`\n",
    "\n",
    "Этот шаг фиксирует направления причинно-следственных связей, которые однозначно следуют из статистических зависимостей. Для каждой тройки $X$ - $Z$ - $Y$ мы проверяем, что $X$ **условно зависит от** $Y$ **по любым** $S$, где $S$ ⊆ $V\\backslash\\{X, Y\\}$ ∪ $Z$ - если это так, то ориентируем тройку как $X$ -> $Z$ <- $Y$ "
   ]
  },
  {
   "cell_type": "code",
   "id": "bb4a2799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:02.596740Z",
     "start_time": "2025-05-03T10:45:02.586459Z"
    }
   },
   "source": [
    "\n",
    "def find_colliders(skeleton: nx.Graph, indep_test, alpha: float = 0.05):\n",
    "    \"\"\"Ориентирует рёбра относительно найденных на графе / в данных v-структур.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dag : nx.DiGraph\n",
    "        Частично оринетированный граф.\n",
    "    \"\"\"\n",
    "    \n",
    "    # pdag - частично ориентированный граф\n",
    "    # Суть функции:\n",
    "    # Создаем пустой граф, добавим узлы и ребра, так, чтобы имитировать неориентированный граф\n",
    "    # Пройдем по всем вершинам рассматривая их как Z - центр v-структуры\n",
    "    \n",
    "    # graph.graph[\"sep_sets\"] = sep_sets - сыграло свою роль \n",
    "    sep_sets = skeleton.graph.get(\"sep_sets\", {})\n",
    "    \n",
    "    pdag = nx.DiGraph()\n",
    "    pdag.add_nodes_from(skeleton.nodes)\n",
    "    for u, v in skeleton.edges:\n",
    "        pdag.add_edge(u, v)\n",
    "        pdag.add_edge(v, u)\n",
    "\n",
    "    for Z in skeleton.nodes:\n",
    "        neighbors = list(skeleton.neighbors(Z))\n",
    "        if len(neighbors) < 2:\n",
    "            continue\n",
    "\n",
    "        # X -> Z <- Y =\n",
    "        for X, Y in combinations(neighbors, 2):\n",
    "            # Проверка, образуют ли X, Z, Y переменные v-структуру\n",
    "            if skeleton.has_edge(X, Y):\n",
    "                continue\n",
    "            \n",
    "            # Проверяем является ли Z - разделяющим множеством\n",
    "            # Если нет - X и Y зависимы при условии Z => v-структура\n",
    "            if Z not in sep_sets.get(frozenset((X, Y)), set()):\n",
    "                if pdag.has_edge(Z, X):\n",
    "                    pdag.remove_edge(Z, X)\n",
    "                if pdag.has_edge(Z, Y):\n",
    "                    pdag.remove_edge(Z, Y)\n",
    "\n",
    "    return pdag\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "id": "bc3e30e8",
   "metadata": {},
   "source": [
    "### 1.3 Функция `orient_edges`\n",
    "\n",
    "На последнем этапе мы ориентируем ребра относительно допущений алгоритма Петера-Кларка. Полный список ориентационных правил (Meek rules) можно найти в [оригинальной статье](https://arxiv.org/pdf/1302.4972).\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:03.590049Z",
     "start_time": "2025-05-03T10:45:02.610290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def orient_edges(g: nx.Graph, sep_sets):\n",
    "    \"\"\"Ориентирует рёбра относительно правил Мика.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dag : nx.DiGraph\n",
    "        Частично оринетированный граф.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Пока находятся рёбра, которые можно ориентировать:\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "\n",
    "        # R1: X→Y, Y–Z, нет ребра между X и Z  ⇒  Y→Z\n",
    "        # Выбираем ребра с направлением X→Y, ищем неориентированное ребро Z-Y, и если X и Z - не связаны, то ориентируем Y→Z.\n",
    "        for X, Y in list(g.edges):\n",
    "            if g.has_edge(Y, X):\n",
    "                continue\n",
    "                \n",
    "            for Z in list(g.predecessors(Y)):\n",
    "                if not g.has_edge(Y, Z):\n",
    "                    continue\n",
    "                if g.has_edge(X, Z) or g.has_edge(Z, X):\n",
    "                    continue\n",
    "                g.remove_edge(Z, Y)\n",
    "                changed = True\n",
    "\n",
    "        # R2: X–Y и есть X→Z→Y  ⇒  X→Y\n",
    "        # Находим неориентированное ребро X-Y, ищем такое Z, что X→Z и Z→Y, после чего ориентируем X→Y\n",
    "        for X, Y in list(g.edges):\n",
    "            if not g.has_edge(Y, X):\n",
    "                continue\n",
    "            for Z in list(g.successors(X)):\n",
    "                if Z == Y or g.has_edge(Z, X):\n",
    "                    continue\n",
    "                if g.has_edge(Z, Y) and not g.has_edge(Y, Z):\n",
    "                    g.remove_edge(Y, X)\n",
    "                    changed = True\n",
    "                    break\n",
    "        \n",
    "        # R3: X→Y, X–W, W–Y, W–Z, Z→Y ⇒ W→Y\n",
    "        # Находим ориентированное ребро X→Y, ищем такое W, что Y–W и X–W, после чего ищем такие Z, что W–Z и Z→Y, если все нашли, то ориентируем ребро W→Y\n",
    "        for X, Y in list(g.edges):\n",
    "            if not g.has_edge(Y, X):\n",
    "                for W in list(g.neighbors(Y)):\n",
    "                    if W in (X, Y):\n",
    "                        continue\n",
    "                    if g.has_edge(Y, W) and g.has_edge(W, Y):\n",
    "                        if g.has_edge(X, W) and g.has_edge(W, X):\n",
    "                            for Z in list(g.neighbors(W)):\n",
    "                                if Z in (X, Y, W):\n",
    "                                    continue\n",
    "                                if g.has_edge(W, Z) and g.has_edge(Z, W):\n",
    "                                    if g.has_edge(Z, Y) and not g.has_edge(Y, Z):\n",
    "                                        g.remove_edge(W, Y)\n",
    "                                        changed = True\n",
    "\n",
    "        # R4: W–X, W–Y, W–Z, Z→Y, Y→X ⇒ W→X\n",
    "        # Находим неориентированные ребра W–X, W–Y, W–Z, и если находим Z → Y и Y → X, то ориентируем W→X\n",
    "        for W, X in list(g.edges):\n",
    "            if not g.has_edge(X, W):\n",
    "                continue\n",
    "            for Y in list(g.neighbors(W)):\n",
    "                if Y in (W, X):\n",
    "                    continue\n",
    "                if not (g.has_edge(W, Y) and g.has_edge(Y, W)):\n",
    "                    continue\n",
    "                for Z in list(g.neighbors(W)):\n",
    "                    if Z in (W, X, Y):\n",
    "                        continue\n",
    "                    if not (g.has_edge(W, Z) and g.has_edge(Z, W)):\n",
    "                        continue\n",
    "                    if g.has_edge(Z, Y) and not g.has_edge(Y, Z):\n",
    "                        if g.has_edge(Y, X) and not g.has_edge(X, Y):\n",
    "                            g.remove_edge(X, W)\n",
    "                            changed = True\n",
    "        \n",
    "    return g\n",
    "    "
   ],
   "id": "4064c78b8e9709b9",
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "eaddebe9",
   "metadata": {},
   "source": [
    "### 1.4 Обертка `pc_algorithm`\n",
    "\n",
    "Соберите отдельные части алгоритма Петера-Кларка внутри одной функции:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d7872f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:03.608546Z",
     "start_time": "2025-05-03T10:45:03.602568Z"
    }
   },
   "source": [
    "\n",
    "def pc_algorithm(data: pd.DataFrame, indep_test, alpha: float = 0.05):\n",
    "    \"\"\"Полный PC‑алгоритм.\"\"\"\n",
    "    skeleton, sep_sets = estimate_skeleton(data, indep_test, alpha)\n",
    "    pdag = find_colliders(skeleton, indep_test, alpha)\n",
    "    pdag = orient_edges(pdag, sep_sets)\n",
    "    \n",
    "    # Теперь необходимо приведение меток узлов к int, а то будет ошибка\n",
    "    index_map = {col: i for i, col in enumerate(data.columns)}\n",
    "    pdag_int = nx.relabel_nodes(pdag, index_map, copy=True)\n",
    "\n",
    "    return pdag_int\n"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "id": "2e1343ae",
   "metadata": {},
   "source": [
    "## Часть 2. Greedy Equivalence Search (GES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5793f96",
   "metadata": {},
   "source": [
    "\n",
    "GES выполняется в два этапа:\n",
    "\n",
    "* **Forward‑phase** — жадно добавляет ребра, улучшая значение функции оценки.\n",
    "* **Backward‑phase** — жадно удаляет ребра, также оптимизируя оценку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69849ed4",
   "metadata": {},
   "source": [
    "Центральной компонентой алгоритма является скоринговая функция, максимизируемая на каждом из этапов GES. В данном домашнем задании это вариант [BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion), рассчитываемый по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\operatorname{BIC}(G , \\mathcal{D})=\\sum_{i=1}^d \\operatorname{BIC}_i, \\\\\n",
    "\\mathrm{BIC}_i=\\ell_i\\left(\\hat{\\theta}_i ; \\mathcal{D}\\right)-\\frac{k_i}{2} \\ln n,\n",
    "$$\n",
    "где $\\ell_i$ - максимизированное лог-правдоподобие узла $X_i$, $k_i$ = $\\mathrm{Pa}_i$, $n$ - объе̄м выборки.\n",
    "\n",
    "Максимизированное лог-правдоподобие\n",
    "\n",
    "$$\n",
    "\\ell_i\\left(\\hat{\\theta}_i; \\mathcal{D}\\right)=-\\frac{n}{2}\\left(\\ln \\hat{\\sigma}_i^2+1+\\ln (2 \\pi)\\right)\n",
    "$$\n",
    "\n",
    "расчитывается посредством построения регрессии родителей вершины $i$ ($\\mathrm{Pa}_i$) относительно каждой вершины $i$:\n",
    "\n",
    "$$\n",
    "X_i=\\beta_{i 0}+\\sum_{j \\in \\mathrm{Pa}_i} \\beta_{i j} X_j+\\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}\\left(0, \\sigma_i^2\\right).\n",
    "$$\n",
    "Оценив значения $\\beta_{i j}$, получим \n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_i^2=\\mathrm{\\sum(y-\\hat{y})^2} / n.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c5816c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:03.627474Z",
     "start_time": "2025-05-03T10:45:03.619143Z"
    }
   },
   "source": [
    "def bic_score(dag: nx.DiGraph, data: pd.DataFrame):\n",
    "    \"\"\"Вычисляет BIC‑скор поданного на вход DAG.\"\"\"\n",
    "    \n",
    "    # Реализуем bic_score для оценки качества DAG графа\n",
    "    \n",
    "    \n",
    "    # total - BIC(G,D)\n",
    "    # n - объем выборки\n",
    "    # ln_n - часть штрафа\n",
    "    total = 0.0\n",
    "    n = len(data)\n",
    "    ln_n = 1/2 * np.log(n)\n",
    "    \n",
    "    # Пройдемся по всем вершинам, определим вектор значений (y) каждой из них, а также найдем их родителей (parents)\n",
    "    for node in dag.nodes:\n",
    "        y = data[node].to_numpy()\n",
    "        parents = list(dag.predecessors(node))\n",
    "\n",
    "        # Если у узла есть родители, то построим регрессию родителей\n",
    "        # X_i = β_0 + SUM_j∈Pa_i (β_j * X_j) + ε_i \n",
    "        # y_pred = X * β\n",
    "        # Если родителей нет, то просто предсказываем средним значением\n",
    "        # y_pred = 1/n SUM_n,i=1 (y_i) \n",
    "        if parents:\n",
    "            X = data[parents].to_numpy()\n",
    "            X = np.column_stack([np.ones(n), X]) \n",
    "            beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "            y_pred= X @ beta\n",
    "        else:\n",
    "            y_pred = np.full_like(y, y.mean())\n",
    "            \n",
    "        # Среднеквадратичная ошибка или оценка дисперсии остатков sigma2\n",
    "        # sigma2 = 1/n SUM_n,i=1 (y_i - y_pred)^2\n",
    "        sigma2 = np.mean((y - y_pred) ** 2)\n",
    "\n",
    "        # Вычислим лог-правдоподобие\n",
    "        # ll = - n/2 * (ln(sigma2) + 1 + ln(2 * pi))\n",
    "        ll = - n/2 * (np.log(sigma2) + 1 + np.log(2 * np.pi))\n",
    "\n",
    "        # Рассчитаем BIC узла\n",
    "        # bic_i = ll - k_i/2 * ln(n)\n",
    "        k_i = len(parents)\n",
    "        bic_i = ll - k_i/2 * np.log(n)\n",
    "        total += bic_i\n",
    "\n",
    "    return total\n"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "id": "a25af234",
   "metadata": {},
   "source": [
    "### 2.1 Функция `ges_forward_phase`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a415fa25",
   "metadata": {},
   "source": [
    "Forward-фаза алгоритма GES заключается в пошаговом добавлении рёбер к пустому графу таким образом, чтобы максимизировать прирост BIC на каждом шаге; процесс продолжается, пока ни одно возможное изменение структуры графа не улучшит BIC."
   ]
  },
  {
   "cell_type": "code",
   "id": "75807b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:03.665408Z",
     "start_time": "2025-05-03T10:45:03.658236Z"
    }
   },
   "source": [
    "def ges_forward_phase(data: pd.DataFrame, score_func):\n",
    "    \"\"\"Возвращает CPDAG после forward фазы.\"\"\"\n",
    "    \n",
    "    # Жадно добавляет рёбра в пустой граф, каждое из которых наиболее улучшает BIC-оценку\n",
    "    # Создадим пустой граф, вычислим BIC\n",
    "    variables = list(data.columns)\n",
    "    dag = nx.DiGraph()\n",
    "    dag.add_nodes_from(variables)\n",
    "    \n",
    "    current_score = score_func(dag, data)\n",
    "\n",
    "    while True:\n",
    "        best_edge = None\n",
    "        best_delta = 0.0\n",
    "\n",
    "        # Будем искать covered дугу с лучшей BIC оценкой\n",
    "        for X in variables:\n",
    "            for Y in variables:\n",
    "                if X == Y or dag.has_edge(X, Y):\n",
    "                    continue\n",
    "                # Проверка на цикл\n",
    "                if nx.has_path(dag, Y, X):\n",
    "                    continue\n",
    "                \n",
    "                # Добавляем, считаем BIC_i, смотрим прирост, удаляем\n",
    "                dag.add_edge(X, Y)\n",
    "                new_score = score_func(dag, data)\n",
    "                delta = new_score - current_score\n",
    "                dag.remove_edge(X, Y)\n",
    "\n",
    "                if delta > best_delta:\n",
    "                    best_delta = delta\n",
    "                    best_edge = (X, Y)\n",
    "\n",
    "        if best_delta > 0 and best_edge:\n",
    "            dag.add_edge(*best_edge)\n",
    "            current_score += best_delta\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return dag\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "7a7fa76e",
   "metadata": {},
   "source": [
    "### 2.2 Функция `ges_backward_phase`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b1c00",
   "metadata": {},
   "source": [
    "Backward-фаза начинается с графа, полученного после forward-фазы -- на данном этапе ребра удаляются до тех пор, пока изменение структуры графа не приводит к ухудшению BIC."
   ]
  },
  {
   "cell_type": "code",
   "id": "ec517195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:03.686822Z",
     "start_time": "2025-05-03T10:45:03.681811Z"
    }
   },
   "source": [
    "def ges_backward_phase(cpdag: nx.Graph, data: pd.DataFrame, score_func):\n",
    "    \"\"\"Возвращает CPDAG после backward фазы.\"\"\"\n",
    "    \n",
    "    # Жадное удаление рёбер, если это улучшает BIC\n",
    "    # Начинаем с графа после forward и удаляем ребро, если это увеличивает BIC\n",
    "    dag = cpdag.copy()\n",
    "    current_score = score_func(dag, data)\n",
    "\n",
    "    while True:\n",
    "        best_edge = None\n",
    "        best_delta = 0.0\n",
    "        \n",
    "        # Перебираем все ориентированные ребра, временно убираем ребро, если не образовалось циклов, высчитываем BIC, смотрим прирост, возвращаем удаленное ребро\n",
    "        for X, Y in list(dag.edges):\n",
    "            dag.remove_edge(X, Y)\n",
    "            \n",
    "            # Проверка на циклы\n",
    "            if nx.is_directed_acyclic_graph(dag):\n",
    "                new_score = score_func(dag, data)\n",
    "                delta = new_score - current_score\n",
    "                if delta > best_delta:\n",
    "                    best_delta = delta\n",
    "                    best_edge = (X, Y)\n",
    "            dag.add_edge(X, Y)\n",
    "\n",
    "        if best_delta > 0 and best_edge:\n",
    "            dag.remove_edge(*best_edge)\n",
    "            current_score += best_delta\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return dag\n"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "15d4a540",
   "metadata": {},
   "source": [
    "### 2.3 Обертка `ges_algorithm`\n",
    "\n",
    "Соберите отдельные части алгоритма GES внутри одной функции:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4cf34b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:03.705391Z",
     "start_time": "2025-05-03T10:45:03.700975Z"
    }
   },
   "source": [
    "\n",
    "def ges_algorithm(data: pd.DataFrame, score_func):\n",
    "    \"\"\"Полная реализация GES.\"\"\"\n",
    "    forward_dag = ges_forward_phase(data, score_func)\n",
    "    final_dag = ges_backward_phase(forward_dag, data, score_func)\n",
    "    return final_dag\n"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "id": "ce9dc682",
   "metadata": {},
   "source": [
    "## Проверка корректности\n",
    "\n",
    "В этом разделе мы протестируем реализованную вами версию PC на синтетическом датасете с известной структурой + сравним с реализацией из пакета **causal‑learn**:"
   ]
  },
  {
   "cell_type": "code",
   "id": "14444b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.579103Z",
     "start_time": "2025-05-03T10:45:03.724213Z"
    }
   },
   "source": "!pip install -q causal-learn ",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "1998443d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.595615Z",
     "start_time": "2025-05-03T10:45:09.590908Z"
    }
   },
   "source": [
    "from numpy.random import randn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.search.ScoreBased.GES import ges"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "6f83353d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.619630Z",
     "start_time": "2025-05-03T10:45:09.608375Z"
    }
   },
   "source": [
    "def simulate(n_samples):   \n",
    "    x1 = randn(n_samples)\n",
    "    x2 = randn(n_samples)\n",
    "    x3 = randn(n_samples)\n",
    "    x5 = x1 + x2 + randn(n_samples)\n",
    "    x4 = x5 + randn(n_samples)\n",
    "    x6 = 0.8*x5 + x2 + x3 + randn(n_samples)\n",
    "    x7 = 0.8 * x6 + randn(n_samples)\n",
    "    return pd.DataFrame({ \"x1\": x1, \"x2\": x2, \"x3\": x3,\"x4\": x4, \"x5\":x5, \"x6\":x6, \"x7\":x7})\n",
    "\n",
    "n_samples = 10000\n",
    "data = simulate(n_samples)"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "13d8a5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.635648Z",
     "start_time": "2025-05-03T10:45:09.631193Z"
    }
   },
   "source": [
    "graph_gt = nx.DiGraph([\n",
    "    ['x1', 'x5'],\n",
    "    ['x2', 'x5'],\n",
    "    ['x5', 'x4'],\n",
    "    ['x5', 'x6'],\n",
    "    ['x2', 'x6'],\n",
    "    ['x3', 'x6'],\n",
    "    ['x6', 'x7']\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "57144400",
   "metadata": {},
   "source": [
    "Зафиксируем уровень значимости:"
   ]
  },
  {
   "cell_type": "code",
   "id": "672c2750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.651133Z",
     "start_time": "2025-05-03T10:45:09.647135Z"
    }
   },
   "source": [
    "alpha = 0.05"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "94352307",
   "metadata": {},
   "source": [
    "Результаты PC из causal-learn:"
   ]
  },
  {
   "cell_type": "code",
   "id": "289d71f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.724168Z",
     "start_time": "2025-05-03T10:45:09.663202Z"
    }
   },
   "source": [
    "alpha = 0.05\n",
    "\n",
    "pc_graph_cl = pc(data.to_numpy(), alpha=alpha, node_names=data.columns)\n",
    "pc_graph_cl.to_nx_graph()\n",
    "\n",
    "g = pc_graph_cl.nx_graph\n",
    "print(g)\n",
    "print(g.edges)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2517b9d67a7946dd8259388a17a7d6fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 7 nodes and 7 edges\n",
      "[(0, np.int64(4)), (1, np.int64(4)), (1, np.int64(5)), (2, np.int64(5)), (4, np.int64(3)), (4, np.int64(5)), (5, np.int64(6))]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "id": "8bd75c4d",
   "metadata": {},
   "source": [
    "Результаты PC, реализованного вами:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8e820a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.883110Z",
     "start_time": "2025-05-03T10:45:09.739451Z"
    }
   },
   "source": [
    "# Запуск PC-алгоритма, реализованного вручную\n",
    "pc_graph = pc_algorithm(data, indep_test, alpha)\n",
    "print(pc_graph)\n",
    "print(pc_graph.edges)\n",
    "\n",
    "# Сравнение с causal-learn\n",
    "assert set(pc_graph.edges) == set(g.edges)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 7 nodes and 7 edges\n",
      "[(0, 4), (1, 4), (1, 5), (2, 5), (4, 3), (4, 5), (5, 6)]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "ae4fe10e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T10:45:09.974832Z",
     "start_time": "2025-05-03T10:45:09.971367Z"
    }
   },
   "source": [
    "assert set(pc_graph.edges) == set(g.edges)"
   ],
   "outputs": [],
   "execution_count": 67
  }
 ],
 "metadata": {
  "description": "Полный ноутбук с дополнительными комментариями и валидацией.",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
